"Standard Errors Above The Null"',
ylab = 'Probability',
main = 't-Distribution under the Null',
typ = 'l', lwd = 3)
abline(v = crit.values, lty = 2, col = 'red')
lines(t.values[t.values < crit.values[1]],
t.dist[t.values < crit.values[1]],
col = 'red', lwd = 3)
lines(t.values[t.values > crit.values[2]],
t.dist[t.values > crit.values[2]],
col = 'red', lwd = 3)
abline(v = t.male, col = 'blue')
p.value.male <- 1-pt(t.male, df = n.male-1) + pt(-t.male, df = n.male-1)
print(p.value.male)
alpha <- 0.05
ci.t.values <- qt(c(alpha/2, 1-alpha/2), df = n.male - 1)
ci.Xbar.95 <- Xbar.male + ci.t.values*SE.Xbar.male
ci.Xbar.95
t.test(females$Height_cm,
mu = mu_0female,
conf.level = 0.99)
#Checkpoint 4:
t.test(males$Height_cm,
mu = mu_0male,
conf.level = 0.95)
mrna.df <- read.csv(file = 'COVID_mRNA.csv')
str(mrna.df)
mrna.df$Timepoint <- as.factor(mrna.df$Timepoint)
nat.inf.titre <- mrna.df$Antibody.Titre[mrna.df$Group == 'Natural Infection']
boxplot(nat.inf.titre,
main = 'Distribution of Antibody Titres',
xlab = 'Prior Infection',
ylab = 'Antibody Titre')
stripchart(nat.inf.titre, add = T,
vertical = T, pch = 19, method = 'jitter')
qqnorm(nat.inf.titre)
qqline(nat.inf.titre)
boxplot(log10(nat.inf.titre),
main = 'Distribution of Antibody Titres',
xlab = 'Prior Infection',
ylab = 'log 10 Antibody Titre')
stripchart(log10(nat.inf.titre),
add = T,
vertical = T, pch = 19, method = 'jitter')
qqnorm(log10(nat.inf.titre))
qqline(log10(nat.inf.titre))
boxplot(log10(Antibody.Titre) ~ Group + Timepoint,
data = mrna.df,
at = 1:2,
xlim = c(0.5, 4.5),
xaxt = 'n',
xlab = 'Group',
main = 'Antibody Titre Responses in Moderna Vaccine Trial',
ylab = 'log 10 Antibody Titre')
stripchart(log10(Antibody.Titre) ~ Group + Timepoint,
data = mrna.df,
at = 1:2, vertical = T, pch = 19,
add = T, method = 'jitter')
boxplot(log10(nat.inf.titre),
at = 4,
vertical = T, add = T)
stripchart(log10(nat.inf.titre),
at = 4,
vertical = T,
pch = 19,
add = T,
method = 'jitter')
axis(1, at = c(1,2,4),
labels = c("Vaccine 15", "Vaccine 57", "Prior Infection"))
vaccine.15 <- subset(mrna.df, subset = (Group == 'Vaccine' & Timepoint == '15'))
t.test(log10(vaccine.15$Antibody.Titre),
log10(nat.inf.titre), # log titres of natural infection group
conf.level = 0.95)
boxplot(log10(Antibody.Titre) ~ Group + Timepoint,
data = mrna.df,
at = 1:2,
xaxt = 'n',
xlab = 'Group',
main = 'Antibody Titre Responses in Moderna Vaccine Trial',
ylab = 'log 10 Antibody Titre')
stripchart(log10(Antibody.Titre) ~ Group + Timepoint,
data = mrna.df,
at = 1:2, vertical = T, pch = 19,
add = T, method = 'jitter')
axis(1, at = c(1,2),
labels = c("15 Days Post Vaccine", "57 Days Post Vaccine"))
boxplot(log10(Antibody.Titre) ~ Group + Timepoint,
data = mrna.df,
at = 1:2,
xaxt = 'n',
xlab = 'Group',
main = 'Antibody Titre Responses in Moderna Vaccine Trial',
ylab = 'log 10 Antibody Titre')
axis(1, at = c(1,2),
labels = c("15 Days Post Vaccine", "57 Days Post Vaccine"))
ids <- unique(mrna.df$Individual.id)
for (i in 1:length(ids)){
ind.df <- subset(mrna.df, subset = Individual.id == ids[i])
points(c(1,2),
log10(c(ind.df$Antibody.Titre[ind.df$Timepoint == '15'],
ind.df$Antibody.Titre[ind.df$Timepoint == '57'])),
pch = 19, typ = 'b')
}
day.15 <- subset(mrna.df, subset = Timepoint == '15')
day.57 <- subset(mrna.df, subset = Timepoint == '57')
day.15[order(day.15$Individual.id),]
day.57[order(day.57$Individual.id),]
differences <- log10(day.57$Antibody.Titre) - log10(day.15$Antibody.Titre)
ind.diff.df <- data.frame(day.15$Individual.id[order(day.15$Individual.id)], differences)
ind.diff.df
boxplot(differences, ylab = 'Differences in Antibody Titre From Day 15 to 57',
main = 'Distribution of Antibody Titre Diffferences', vertical = T,
ylim = c(0,2))
stripchart(differences, vertical = T, pch = 19, method = 'jitter', add = T)
abline(h = 0, col = 'red', lty = 2)
t.test(log(day.57$Antibody.Titre), log(day.15$Antibody.Titre),
paired = TRUE)
t.test(ind.diff.df$differences)
two.sample.mdl <- t.test(log10(vaccine.15$Antibody.Titre),
log10(nat.inf.titre),
conf.level = 0.95)
two.sample.mdl$estimate
(effect.size <- two.sample.mdl$estimate[2] - two.sample.mdl$estimate[1])
sd.vaccine <- sd(log10(vaccine.15$Antibody.Titre))
sd.prior <- sd(log10(nat.inf.titre))
mu.vaccine <-two.sample.mdl$estimate[1]
sigma.vaccine <- sd.vaccine
mu.prior <- two.sample.mdl$estimate[2]
sigma.prior <- sd.prior
alpha <- 0.5
sample.sizes <- seq(from = 15, to = 50, by = 2)
tests <- 1000
fraction.tests.rejected <- rep(NA, length(sample.sizes))
for (i in 1:length(sample.sizes)){
test.p <- rep(NA,tests)
n <- sample.sizes[i]
for (j in 1:tests){
vaccine.sample <- rnorm(n, mu.vaccine, sigma.vaccine)
prior.sample <- rnorm(n, mu.prior, sigma.prior)
boot.mdl <- t.test(vaccine.sample, prior.sample)
test.p[j] <- boot.mdl$p.value
}
fraction.tests.rejected[i] <- sum(test.p < alpha)/tests
}
plot(sample.sizes, fraction.tests.rejected, pch = 19,
typ = 'b', xlab = 'Sample Size',
ylab = 'Power (Fraction of Tests Rejecting Null)',
main = 'T-test Power Analysis',
ylim = c(0.5,1))
#Checkpoint 8:
#For an effect size of 0.0016 the number of samples needed is very large greater than 100,000.
sd.vaccine <- sd(log10(vaccine.15$Antibody.Titre))
sd.prior <- sd(log10(nat.inf.titre))
mu.vaccine <- 1
sigma.vaccine <- sd.vaccine
mu.prior <- 0.9984
sigma.prior <- sd.prior
alpha <- 0.5
sample.sizes <- seq(from = 50000, to = 100000, by = 25000)
tests <- 1000
fraction.tests.rejected <- rep(NA, length(sample.sizes))
#For an effect size of 0.016 you need a sample size od 5,000 to detect a difference with 90% chance in this case.
sd.vaccine <- sd(log10(vaccine.15$Antibody.Titre))
sd.prior <- sd(log10(nat.inf.titre))
mu.vaccine <- 0.1
sigma.vaccine <- sd.vaccine
mu.prior <- 0.084
sigma.prior <- sd.prior
alpha <- 0.5
sample.sizes <- seq(from = 4000, to = 5000, by = 100)
tests <- 1000
fraction.tests.rejected <- rep(NA, length(sample.sizes))
for (i in 1:length(sample.sizes)){
test.p <- rep(NA,tests)
n <- sample.sizes[i]
for (j in 1:tests){
vaccine.sample <- rnorm(n, mu.vaccine, sigma.vaccine)
prior.sample <- rnorm(n, mu.prior, sigma.prior)
boot.mdl <- t.test(vaccine.sample, prior.sample)
test.p[j] <- boot.mdl$p.value
}
fraction.tests.rejected[i] <- sum(test.p < alpha)/tests
}
plot(sample.sizes, fraction.tests.rejected, pch = 19,
typ = 'b', xlab = 'Sample Size',
ylab = 'Power (Fraction of Tests Rejecting Null)',
main = 'T-test Power Analysis',
ylim = c(0.5,1))
#For an effect size of 1.6 you any sample size works to detect a difference with 90% chance in this case.
sd.vaccine <- sd(log10(vaccine.15$Antibody.Titre))
sd.prior <- sd(log10(nat.inf.titre))
mu.vaccine <- 2.6
sigma.vaccine <- sd.vaccine
mu.prior <- 1
sigma.prior <- sd.prior
alpha <- 0.5
sample.sizes <- seq(from = 10, to = 100, by = 10)
tests <- 1000
fraction.tests.rejected <- rep(NA, length(sample.sizes))
for (i in 1:length(sample.sizes)){
test.p <- rep(NA,tests)
n <- sample.sizes[i]
for (j in 1:tests){
vaccine.sample <- rnorm(n, mu.vaccine, sigma.vaccine)
prior.sample <- rnorm(n, mu.prior, sigma.prior)
boot.mdl <- t.test(vaccine.sample, prior.sample)
test.p[j] <- boot.mdl$p.value
}
fraction.tests.rejected[i] <- sum(test.p < alpha)/tests
}
plot(sample.sizes, fraction.tests.rejected, pch = 19,
typ = 'b', xlab = 'Sample Size',
ylab = 'Power (Fraction of Tests Rejecting Null)',
main = 'T-test Power Analysis',
ylim = c(0.5,1))
mu_0female<- 163.1
mu_0male<- 175.3
maleheights.df <- subset(heights.df, subset=(Gender=='Male'))
femaleheights.df <-subset(heights.df, subset=(Gender=='Female'))
par(mfrow = c(1,2))
stripchart(femaleheights.df$Height, method = 'jitter', xlab='Height (cm)', main="Female Actresses Heights")
abline(v=mu_0female, col = 'red', lwd = 3, lty=3)
stripchart(maleheights.df$Height, method = 'jitter', xlab='Height (cm)', main="Male Actors Heights")
abline(v=mu_0male, col = 'red', lwd = 3,lty=3)
par(mfrow = c(1,1))
n.females <- length(heights.df$Height_cm[heights.df$Gender == 'Female'])
t.values <- seq(from = -5, to = 5, length = 1000)
t.dist <- dt(t.values, df = n.females -1)
plot(t.values, t.dist,
xlab = 'Possible t-statistics under null hypothesis
"Standard Errors Above The Null"',
ylab = 'Probability',
main = 't-Distribution under the Null',
typ = 'l', lwd = 3)
alpha <- 0.05
(crit.values <- qt(c(alpha/2, 1 - alpha/2), df = n.females - 1))
plot(t.values, t.dist,
xlab = 'Possible t-statistics under null hypothesis
"Standard Errors Above The Null"',
ylab = 'Probability',
main = 't-Distribution under the Null',
typ = 'l', lwd = 3)
abline(v = crit.values, lty = 2, col = 'red')
lines(t.values[t.values < crit.values[1]],
t.dist[t.values < crit.values[1]],
col = 'red', lwd = 3)
lines(t.values[t.values > crit.values[2]],
t.dist[t.values > crit.values[2]],
col = 'red', lwd = 3)
mu_0female<- 163.1
mu_0male<- 175.3
females <- subset(heights.df, subset = Gender == 'Female')
(Xbar.female <- mean(females$Height_cm))
(s.female <- sd(females$Height_cm))
(n.female <- length(females$Height_cm))
(SE.Xbar.female <- s.female/sqrt(n.female))
(t.female <- (Xbar.female - mu_0female)/SE.Xbar.female)
plot(t.values, t.dist,
xlab = 'Possible t-statistics under null hypothesis
"Standard Errors Above The Null"',
ylab = 'Probability',
main = 't-Distribution under the Null',
typ = 'l', lwd = 3)
abline(v = crit.values, lty = 2, col = 'red')
lines(t.values[t.values < crit.values[1]],
t.dist[t.values < crit.values[1]],
col = 'red', lwd = 3)
lines(t.values[t.values > crit.values[2]],
t.dist[t.values > crit.values[2]],
col = 'red', lwd = 3)
abline(v = t.female, col = 'blue')
p.value.female <- 1 - pt(t.female, df = n.female - 1) +
pt(-t.female, df = n.female - 1)
print(p.value.female)
alpha <- 0.01
ci.t.values <- qt(c(alpha/2, 1-alpha/2), df = n.female - 1)
ci.Xbar.99 <- Xbar.female + ci.t.values*SE.Xbar.female
ci.Xbar.99
## checkpoint 7
alpha <- 0.05
power <- 0.90
sd_value <- 0.2
small_effect <- power.t.test(delta = 0.0016, sd = sd_value, power = power, sig.level = alpha, type = "two.sample")
moderate_effect <- power.t.test(delta = 0.016, sd = sd_value, power = power, sig.level = alpha, type = "two.sample")
large_effect <- power.t.test(delta = 1.6, sd = sd_value, power = power, sig.level = alpha, type = "two.sample")
small_effect$n
moderate_effect$n
large_effect$n
setwd("/Users/nicholaskortessis/Library/CloudStorage/GoogleDrive-kortessn@wfu.edu/My Drive/Import/Wake Forest/Teaching/24-25/2025 - Spring/BIO 380/Lab/Wk12")
df.k<-read.csv(file = "knees.csv")
str(df.k)
##Checkpoint 1: What are the names of each treatment and how many individuals are in each group?
## The names are Knees,eyes, control . Control has 8 eyes has 7 knees has 7
boxplot(shift ~ treatment, data = df.k)
boxplot(shift ~ treatment, data = df.k)
stripchart(subset(df.k, subset = treatment == 'control')$shift, at = 1, add = T,
vertical = T, pch = 19, method = 'jitter')
stripchart(subset(df.k, subset = treatment == 'eyes')$shift, at = 2, add = T,
vertical = T, pch = 19, method = 'jitter')
stripchart(subset(df.k, subset = treatment == 'knee')$shift, at = 3, add = T,
vertical = T, pch = 19, method = 'jitter')
library(viridisLite)
cols <- viridis(3, begin = 0.2, end = 0.8)
boxplot(shift ~ treatment, data = df.k, col = cols)
stripchart(subset(df.k, subset = treatment == 'control')$shift, at = 1, add = T,
vertical = T, pch = 19, method = 'jitter')
stripchart(subset(df.k, subset = treatment == 'eyes')$shift, at = 2, add = T,
vertical = T, pch = 19, method = 'jitter')
stripchart(subset(df.k, subset = treatment == 'knee')$shift, at = 3, add = T,
vertical = T, pch = 19, method = 'jitter')
m1 <- lm(shift~treatment, data=df.k)
install.packages("car")
library(car)
m1 <- lm(shift ~ treatment, data = your_data)
## Checkpoint 2: What is the estimate of variation that is attributable to the groups and what is the estimate of variation that is attributable to something other than groups?
## Variation attributable to the groups: Mean Square = 3.612 Variation attributable to something other than groups: Mean Square = 0.496
F.values <- seq(from = 0, to = 10, length = 1000)
F.prob <- df(F.values, df1 = 2, df2 = 19)
plot(F.values, F.prob, xlab = 'F-statistic', ylab = 'Probability Density',
main = 'F Distribution for 3 groups and 22 individuals',
type = 'l', lwd = 2)
#Store ANOVA results
m1.ANOVA <- Anova(m1)
# Pull out and plot the F-value
abline(v = m1.ANOVA$'F value', lty = 2, col = 'red', lwd = 2)
(p.value <- 1-pf(m1.ANOVA$'F value', df1 = 2, df2 = 19))
par(mfrow=c(2,2), mar=c(4,4,2,1))
plot(m1)
##Checkpoint 3: Does our model match the assumptions well?
## Yes the lines and dots match up well with what they are supposed to on the graph
?TukeyHSD
TukeyHSD(aov(m1))
par(mfcol = c(1,1))
plot(TukeyHSD(aov(m1)))
pairwise.t.test(df.k$shift, df.k$treatment, p.adjust.method="BH")
##Checkpoint 5: What do you conclude from this study?
## The Eye treatment has a unique difference in the effect compared to the knees and control treatment
## Checkpoint 6: Load the data set “snailgrowth_bal.csv”
setwd("/Users/altonwise/Downloads")
getwd()
df.g<- read.csv("snailgrowth_bal.csv")
df.g$temp.C <- as.factor(df.g$temp.C)
df.g$sal.ppm <- as.factor(df.g$sal.ppm)
str(df.g)
par(mfrow=c(1,1))
boxplot(growth.mm~sal.ppm*temp.C, data=df.g)
tapply(df.g$growth.mm, list(df.g$sal.ppm, df.g$temp.C), length)
m2 <- lm(growth.mm~sal.ppm*temp.C, data=df.g)
par(mfrow=c(2,2), mar=c(4,4,4,1))
plot(m2)
summary(aov(m2))
Anova(m2)
TukeyHSD(aov(m2))
plot(TukeyHSD(aov(m2)))
group <- paste( df.g$sal.ppm,df.g$temp.C, sep=".")
pairwise.t.test(df.g$growth.mm, group, p.adjust.method = "bonferroni")
tapply(df.g$growth.mm, group, mean)
setwd("/Users/nicholaskortessis/Library/CloudStorage/GoogleDrive-kortessn@wfu.edu/My Drive/Import/Wake Forest/Teaching/24-25/2025 - Spring/BIO 380/Lab/Wk14")
biopsy.df <- read.csv('biopsy_diag.csv')
##### CHECKPOINT 1 #####
# Create value for plotting the logistic function
x <- seq(from = -6, to = 6, length = 100)
y <- 1 / (1 + exp(-x))
# x = 0 ; y = 0.5
x <- 0
1 / (1 + exp(-x))
# x = -1 ; y = 0.27
x <- -1
1 / (1 + exp(-x))
# x = 1 ; y = 0.73
x <- 1
1 / (1 + exp(-x))
# x = 2 ; y = 0.88
x <- 2
1 / (1 + exp(-x))
# x = -4 ; y = 0.018
x <- -4
1 / (1 + exp(-x))
##### CHECKPOINT 2 #####
p <- seq(from = 0.001, to = 0.999, length = 1000)
log.odds <- log(p/(1-p))
p <- 0.1
log(p/(1-p)) # -2.2
p <- 0.9
log(p/(1-p)) # 2.2
p <- 0.25
log(p/(1-p)) # -1.1
p <- 0.75
log(p/(1-p)) # 1.1
p <- 0.5
log(p/(1-p)) # 0
p <- 0.01
log(p/(1-p)) # -4.6
p <- 0.99
log(p/(1-p)) # 4.6
##### CHECKPOINT 3 #####
install.packages('ciTools')
library(ciTools)
diagnosis01 <- ifelse(biopsy.df$diagnosis == "M", 1, 0)
model <- glm(factor(diagnosis) ~ smoothness_mean, data = biopsy.df, family = binomial())
summary(model) #Bo = -6.38 B1 = 60.09
beta0 <- coef(model)[1]
beta1 <- coef(model)[2]
# Make radii
smooth <- seq(from = 0, to = 0.3, length = 1000)
# Make log-odds line
log.odds.p <- beta0 + beta1*smooth
# Convert to probability using inverse logit function
p <- exp(log.odds.p)/(1+exp(log.odds.p))
#What is the odds ratio of a unit increase in the smoothness of a sample on a malignant diagnosis?
odds_ratios <- exp(cbind(OR = coef(model), confint(model)))
odds_ratios
#What is the probability of a malignant diagnosis for a sample with the average smoothness?
log.odds.p.ave.smooth <- coef(model)[1] + coef(model)[2]*mean(biopsy.df$smoothness_mean)
p.ave.smooth <- exp(log.odds.p.ave.smooth)/(1+exp(log.odds.p.ave.smooth))
p.ave.smooth
#What is the smoothness of the tumor sample that leads to equal odds of a malignant diagnosis?
(X.even.odds <- -coef(model)[1]/coef(model)[2])
#Figure
plot(biopsy.df$smoothness_mean, jitter(diagnosis01, amount = 0.05), pch = 21, bg = 'royalblue', xlab = 'Average Smoothness', ylab = 'Diagnosis')
# CI
best.fit.line <- predict.glm(model, newdata = data.frame(smoothness_mean = smooth), family = binomial(), type = 'response')
#Figure
plot(biopsy.df$smoothness_mean, jitter(diagnosis01, amount = 0.05), pch = 21, bg = 'royalblue', xlab = 'Average Smoothness', ylab = 'Diagnosis')
# CI
best.fit.line <- predict.glm(model, newdata = data.frame(smoothness_mean = smooth), family = binomial(), type = 'response')
library(ciTools)
line.ci <- add_ci(df = data.frame(smoothness_mean = smooth), fit = model, alpha = 0.05)
# Adding CI as shaded
polygon(c(smooth, rev(smooth)), c(line.ci$LCB0.025, rev(line.ci$UCB0.975)), col = adjustcolor('royalblue', alpha.f = 0.2), border = NA)
# Add best fit line
lines(smooth, best.fit.line, col = 'royalblue', lwd = 2)
##### CHECKPOINT 4 #####
par(mfcol = c(2,2))
# (n = 5, k = 1)
n <- 5
k <- 1
p <- seq(0, 1, length = 2000)
likelihood <- dbinom(k, n, p)
plot(p, likelihood, type = "l", lwd = 2, xlab = "p", ylab = "Likelihood", main = "(n = 5, k = 1)")
# (n = 500, k = 100)
n <- 500
k <- 100
p <- seq(0, 1, length = 2000)
likelihood <- dbinom(k, n, p)
plot(p, likelihood, type = "l", lwd = 2, xlab = "p", ylab = "Likelihood", main = "(n = 500, k = 100)")
# (n = 5, k = 4)
n <- 5
k <- 4
p <- seq(0, 1, length = 2000)
likelihood <- dbinom(k, n, p)
plot(p, likelihood, type = "l", lwd = 2, xlab = "p", ylab = "Likelihood", main = "(n = 5, k = 4)")
# (n = 500, k = 400)
n <- 500
k <- 400
p <- seq(0, 1, length = 2000)
likelihood <- dbinom(k, n, p)
plot(p, likelihood, type = "l", lwd = 2, xlab = "p", ylab = "Likelihood", main = "(n = 500, k = 400)")
# Checkpoint 3: #########################
model2 <- glm(factor(diagnosis) ~ smoothness_mean,
data = biopsy.df,
family = binomial())
smoothnesses <- seq(from = 0, to = 0.2, length = 1000)
best.fit.line2 <- predict.glm(model2,
newdata = data.frame(smoothness_mean = smoothnesses),
family = binomial(),
type = 'response')
line.ci2 <- add_ci(df = data.frame(smoothness_mean = smoothnesses),
fit = model2,
alpha = 0.05)
# 5. Plot the data
plot(biopsy.df$smoothness_mean,
jitter(diagnosis01, amount = 0.05), # jitter points a bit
pch = 21, bg = 'royalblue',
xlab = 'Average Smoothness',
ylab = 'Diagnosis')
par(mfcol = c(1,1))
# 5. Plot the data
plot(biopsy.df$smoothness_mean,
jitter(diagnosis01, amount = 0.05), # jitter points a bit
pch = 21, bg = 'royalblue',
xlab = 'Average Smoothness',
ylab = 'Diagnosis')
# Add best fit line
lines(smoothnesses, best.fit.line2,
col = 'royalblue', lwd = 2)
# Add confidence intervals
lines(smoothnesses, # Radii values we fit
line.ci2$LCB0.025, # Lower confidence bound
col = 'royalblue', lty = 2)
lines(smoothnesses, # Radii values we fit
line.ci2$UCB0.975, # Upper confidence bound
col = 'royalblue', lty = 2)
# Add confidence intervals as a polygon
polygon(c(smoothnesses, rev(smoothnesses)),
c(line.ci2$LCB0.025, rev(line.ci2$UCB0.975)),
col = adjustcolor('royalblue', alpha.f = 0.2),
border = NA)
# 1.
# Because the line has a curve but is relatively flat, smoothness is related
# to the diagnosis but not by a significant amount.
# 2.
# Biopsies are more likely to lead to malignant diagnosis when samples are
# more smooth.
# 3.
odds_ratios2 <- exp(cbind(OR = coef(model2), confint(model2)))
odds_ratios2[2,1]
# 1.244205e+26
# 4.
avg_smoothness <- (mean(biopsy.df$smoothness_mean)) # Find average smoothness
closest_to_avg <- which(abs(best.fit.line2 - avg_smoothness) == min(abs(best.fit.line2 - avg_smoothness))) # Find which smoothness in best fit line is closest to average
best.fit.line2[closest_to_avg]
